{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 38, 38, 3)\n",
      "(57, 38, 38, 3)\n",
      "(57, 38, 38, 3)\n",
      "height: 38\n",
      "width: 38\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "#mnist = input_data.read_data_sets(\"data/\")\n",
    "\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "#__change\n",
    "#Here it is required to load our custom images from data/style_transfer/x and data/style_transfer/y\n",
    "\n",
    "height = 128\n",
    "width = 128\n",
    "pixels = 3\n",
    "resize_frac=0.3\n",
    "\n",
    "#code to load images from the folder style_transfer\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder, images, index):\n",
    "\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            img = cv2.resize(img, (height, width))\n",
    "            img = cv2.resize(img,(0,0), fx=resize_frac, fy=resize_frac)\n",
    "            images[index]=img\n",
    "            index = index + 1\n",
    "    return images\n",
    "\n",
    "x_front = [[]]*1\n",
    "x_fabric = [[]]*57\n",
    "y_front = [[]]*57\n",
    "#print(np.shape(x_front))\n",
    "#print(np.shape(x_fabric))\n",
    "#print(np.shape(y_front))\n",
    "x_front = load_images_from_folder (\"D:/deeplearning/cloudxlab/style_transfer/ml-master/deep_learning/data/style_transfer/x/base/front\", x_front, 0)\n",
    "x_fabric = load_images_from_folder (\"D:/deeplearning/cloudxlab/style_transfer/ml-master/deep_learning/data/style_transfer/x/fabric\", x_fabric, 0)\n",
    "y_front = load_images_from_folder (\"D:/deeplearning/cloudxlab/style_transfer/ml-master/deep_learning/data/style_transfer/y/front\", y_front, 0)\n",
    "\n",
    "#for img in glob.glob(\"data/x/base/front/*.png\"):\n",
    "#    cv_img = cv2.imread(img)\n",
    "    \n",
    "#x_front = [cv2.imread(file) for file in glob.glob(\"data/x/base/front/*.png\")]\n",
    "#x_fabric = [cv2.imread(file) for file in glob.glob(\"data/x/fabric/*.jpg\")]\n",
    "#y_front = [cv2.imread(file) for file in glob.glob(\"data/y/front/*.png\")]\n",
    "\n",
    "#myx-front = cv2.imread(\"data/x/base/front/x_main_front.png\")\n",
    "print(np.shape(x_front))\n",
    "print(np.shape(x_fabric))\n",
    "print(np.shape(y_front))\n",
    "\n",
    "height = np.int32(height*resize_frac)\n",
    "width = np.int32(width*resize_frac)\n",
    "\n",
    "print(\"height:\", height)\n",
    "print(\"width:\", width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 2888, 3)\n",
      "(57, 1444, 3)\n",
      "(57, 8664)\n",
      "(57, 4332)\n"
     ]
    }
   ],
   "source": [
    "x_front = np.array(x_front, dtype=np.float32)/255\n",
    "x_fabric = np.array(x_fabric, dtype=np.float32)/255\n",
    "y_front = np.array(y_front, dtype=np.float32)/255\n",
    "\n",
    "\n",
    "def image_conv_1D2D (img, h, w, p):\n",
    "    image = np.zeros((h, w, p))\n",
    "    #print(np.shape(image))\n",
    "    #print(np.shape(img))\n",
    "    for i in range(0, h):\n",
    "        for j in range(0, w):\n",
    "            #print(i,j)\n",
    "            image[i,j,:] = img[w*i+j, : ];\n",
    "    return image\n",
    "\n",
    "def image_conv_2D1D (image, h, w, p):\n",
    "    img = np.zeros((h*w, p))\n",
    "    #print(np.shape(image))\n",
    "    #print(np.shape(img))\n",
    "    for i in range(0, h):\n",
    "        for j in range(0, w):\n",
    "            #print(i,j)\n",
    "            img[w*i+j, : ] = image[i,j,:]\n",
    "    \n",
    "    return img\n",
    "\n",
    "def input_multiplex(image1, image2):\n",
    "    #todo: pass lengths of the images so as to make the function generic\n",
    "    l1= l2 = height*width\n",
    "    p = pixels\n",
    "    im = np.zeros((2*l1, p))\n",
    "    for i in range (0, l1):\n",
    "        #print(i)\n",
    "        im[2*i, :] = image1[i,:]\n",
    "        im[2*i+1, :] = image2[i,:]\n",
    "    \n",
    "    return im\n",
    "\n",
    "def unroll_RGB(image, length, pixels):\n",
    "    im = np.zeros((length*pixels))\n",
    "    for i in range(0, length):\n",
    "        im[3*i+0] = image[i, 0]\n",
    "        im[3*i+1] = image[i, 1]\n",
    "        im[3*i+2] = image[i, 2]\n",
    "    \n",
    "    return im\n",
    "\n",
    "    \n",
    "    \n",
    "#img = image_conv_2D1D(x_front[0], 128, 128, 3)\n",
    "#print(np.shape(img))\n",
    "\n",
    "#image = image_conv_1D2D(img, 128, 128, 3)\n",
    "#print(np.shape(image))\n",
    "\n",
    "#print(x_front[0].shape)\n",
    "x_front_linear = image_conv_2D1D(x_front[0], height, width, pixels)\n",
    "\n",
    "\n",
    "xt = [[]]*57\n",
    "yt = [[]]*57\n",
    "x_total = [[]]*57\n",
    "y_total = [[]]*57\n",
    "#print(np.shape(x_front_linear))\n",
    "for i in range (0, 57):\n",
    "    x_fabric_linear = image_conv_2D1D(x_fabric[i], height, width, pixels)\n",
    "    xt[i] = input_multiplex(x_front_linear, x_fabric_linear)\n",
    "    #print(i)\n",
    "    x_total[i] = unroll_RGB(xt[i], 2*height*width, pixels)\n",
    "    yt[i] = image_conv_2D1D(y_front[i], height, width, pixels)\n",
    "    y_total[i] = unroll_RGB(yt[i], height*width, pixels)\n",
    "\n",
    "\n",
    "print(np.shape(xt))\n",
    "print(np.shape(yt))\n",
    "\n",
    "print(np.shape(x_total))\n",
    "print(np.shape(y_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34, 8664)\n",
      "(11, 8664)\n",
      "(12, 8664)\n",
      "(34, 4332)\n",
      "(11, 4332)\n",
      "(12, 4332)\n"
     ]
    }
   ],
   "source": [
    "# Divide the training set 57 inputs into train, valid and test\n",
    "\n",
    "#x_train = x_total[0:34][:]\n",
    "x_train, x_valid, x_test = x_total[:34][:], x_total[34:45][:], x_total[45:57][:]\n",
    "y_train, y_valid, y_test = y_total[:34][:], y_total[34:45][:], y_total[45:57][:]\n",
    "\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_valid))\n",
    "print(np.shape(x_test))\n",
    "\n",
    "print(np.shape(y_train))\n",
    "print(np.shape(y_valid))\n",
    "print(np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#__change\n",
    "#n_inputs = 28 * 28  # MNIST\n",
    "#n_hidden1 = 300\n",
    "#n_hidden2 = 100\n",
    "#n_outputs = 10\n",
    "\n",
    "n_inputs = 2*pixels*height * width  # Style_transfer\n",
    "n_outputs = pixels*height*width     #no. of pixels (3 pixels for RGB) for 128*128 image\n",
    "\n",
    "n_hidden1 = n_inputs      # keeping first hidden layer as 4000 neurons\n",
    "n_hidden2 = n_outputs       # keeping second hidden layer as 400 neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:  8664\n",
      "outputs:  4332\n",
      "hidden layer1:  8664\n",
      "hiddden layer2:  4332\n"
     ]
    }
   ],
   "source": [
    "print(\"inputs: \", n_inputs)\n",
    "print(\"outputs: \", n_outputs)\n",
    "print(\"hidden layer1: \", n_hidden1)\n",
    "print(\"hiddden layer2: \", n_hidden2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with tf.variable_scope(\"model\", reuse=True):\n",
    "with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.relu, name=\"hidden1\")\n",
    "    hidden2 = tf.layers.dense(hidden1, n_hidden2, activation=tf.nn.relu, name=\"hidden2\")\n",
    "    outputs = tf.layers.dense(hidden2, n_outputs, name=\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.square(outputs - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "#x = x_train[1:2]\n",
    "#print(np.shape(x))\n",
    "print(np.shape(x_train)[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_examples =  34\n",
      "0 Batch accuracy: 0.33218 Validation accuracy: 0.478375\n",
      "2 Batch accuracy: 0.140259 Validation accuracy: 0.19602\n",
      "4 Batch accuracy: 0.0495633 Validation accuracy: 0.0536372\n",
      "6 Batch accuracy: 0.02715 Validation accuracy: 0.0212123\n",
      "8 Batch accuracy: 0.0220358 Validation accuracy: 0.0156844\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 1\n",
    "num_examples = np.shape(x_train)[0]\n",
    "print(\"num_examples = \", num_examples)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(num_examples // batch_size):\n",
    "            X_batch = x_train[iteration:iteration+batch_size]\n",
    "            y_batch = y_train[iteration:iteration+batch_size]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        if epoch % 2 == 0:\n",
    "            X_valid = x_valid[epoch:epoch+1]\n",
    "            Y_valid = y_valid[epoch:epoch+1]\n",
    "            accuracy = loss\n",
    "            acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "            acc_test = accuracy.eval(feed_dict={X: X_valid, y: y_valid})\n",
    "            print(epoch, \"Batch accuracy:\", acc_train, \"Validation accuracy:\", acc_test)\n",
    "\n",
    "    save_path = saver.save(sess, \"model_ckps/my_model_final.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dog-project]",
   "language": "python",
   "name": "conda-env-dog-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
